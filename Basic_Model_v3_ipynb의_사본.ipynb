{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Model v3.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomYOON/Stock-project/blob/master/Basic_Model_v3_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0hF7M50RySa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCeNc93yecPR",
        "colab_type": "text"
      },
      "source": [
        "# **Mount your drive**\n",
        "본인의 구글 드라이브와 Colab을 연동합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIs8LcpQ2NkM",
        "colab_type": "code",
        "outputId": "fa584c43-a3f9-4780-91c2-e89abae5e563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpbeiVKHV0KG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing data from url\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/Concarne2/stock_data/master/DATA/sk%ED%95%98%EC%9D%B4%EB%8B%89%EC%8A%A4(%EC%88%98%EC%A0%95).csv\"\n",
        "csv_df=pd.read_csv(url)\n",
        "\n",
        "#  0     1    2    3     4      5    6    7\n",
        "# year,month,day,close,volume,start,high,low\n",
        "\n",
        "\n",
        "csv_np_raw = csv_df.to_numpy()\n",
        "row,col = np.shape(csv_np_raw)\n",
        "\n",
        "for i in range(row):\n",
        "  for j in range(3,col):\n",
        "    csv_np_raw[i][j] = csv_np_raw[i][j].replace(\",\",\"\")\n",
        "\n",
        "full_data_np = np.flip(csv_np_raw.astype(int),axis=0)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zRtaPvmzskC",
        "colab_type": "text"
      },
      "source": [
        "# **input data 변경**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILEnJGCGzijW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  0     1    2    3     4      5    6    7\n",
        "# year,month,day,close,volume,start,high,low\n",
        "###################################################\n",
        "data_np = full_data_np[:,[5,3,6,7,4]]      #####여기있는 숫자 변경하면 input data 변경됨#####\n",
        "##################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VswRwOMSLPcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize data\n",
        "\n",
        "#data_min = np.min(data_np[:,1])\n",
        "#data_scale = np.max(data_np[:,1]) - np.min(data_np[:,1])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data_np)\n",
        "data_norm = scaler.transform(data_np)\n",
        "data_norm = np.insert(data_norm,0,np.arange(data_norm.shape[0]),axis=1)\n",
        "#data = torch.from_numpy(data_norm)\n",
        "#plt.plot(data_norm[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTKTvc8yn05A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoreBasicLSTM(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, output_size):\n",
        "    super().__init__()\n",
        "    self.date = output_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = output_size)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(inputs)\n",
        "    output = self.drop(hidden.squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXlAPYcri7LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoreBasicLSTM_timestamp_processing(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, output_size):\n",
        "    super().__init__()\n",
        "    self.date = output_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = output_size)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    input_without_timestamp = inputs[:,:,1:]\n",
        "    batch_size = inputs\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(input_without_timestamp)\n",
        "    output = self.drop(hidden.squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    print(output.size())\n",
        "    output = output.view(self.date,1)\n",
        "    timestamps = torch.from_numpy(np.arange(self.date) + inputs[-1,:,0].item() + 1).view(self.date,1)\n",
        "    \n",
        "    return torch.cat([timestamps,output],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr-WEhdxZilr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_twolayer(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, output_size):\n",
        "    super().__init__()\n",
        "    self.date = output_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden, num_layers = 2, dropout = drop)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = output_size)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(inputs)\n",
        "    output = self.drop(hidden[1,:,:].squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QdItl4_aEga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_sequential(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, num_layer=1):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layer\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden,num_layers = self.num_layers, dropout = drop)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = 1)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(inputs)\n",
        "    output = self.drop(hidden[1,:,:].squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    \n",
        "    return output\n",
        "\n",
        "#str 변환시 함수 이름이 출력되게함\n",
        "  def __str__(self):\n",
        "    return str(LSTM_sequential).split(\".\")[1][:-2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNUIr_wMZNK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(time_steps, date, data_target_batches, model, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  #prediction_list=[]\n",
        "  batch_amount = len(data_target_batches)\n",
        "  batch_size = list(data_target_batches[0][0].size())[1]\n",
        "  model.train()\n",
        "  \n",
        "  for data, target in data_target_batches:\n",
        "    \n",
        "    assert target[0,0,0].item() == (data[-1,0,0].item() + 1)\n",
        "    \n",
        "    optimizer.zero_grad()   \n",
        "    \n",
        "    data_without_timestamp = data[:,:,1:].clone()\n",
        "\n",
        "    all_predictions = []\n",
        "    \n",
        "    for d in range(date):\n",
        "      prediction_batch = model(data_without_timestamp)\n",
        "      all_predictions.append(prediction_batch)\n",
        "      data_last = data_without_timestamp[-1:,:,:].clone()\n",
        "      for b in range(batch_size):\n",
        "        data_last[0,b,1] = prediction_batch[b].item()  \n",
        "\n",
        "\n",
        "      data_without_timestamp = torch.cat((data_without_timestamp[1:,:,:],data_last),axis=0)\n",
        "\n",
        "    target_without_timestamp = torch.squeeze(target[:,:,1])\n",
        "    loss = criterion(target_without_timestamp, torch.cat(all_predictions,axis=1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / batch_amount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8SP9jUcowZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(time_steps, date, data, target, model, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  predictions=[]\n",
        "  \n",
        "  model.eval()\n",
        "  num_tries = list(target.size())[1] - (date - 1)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i in range(num_tries):\n",
        "\n",
        "      starting_date = data[i:i+time_steps,:,:][-1,0,0].item()\n",
        "\n",
        "      input_data = data[i:i+time_steps,:,1:]\n",
        "\n",
        "      all_predictions = []\n",
        "\n",
        "      for d in range(date):\n",
        "        prediction = model(input_data)\n",
        "        all_predictions.append(prediction)\n",
        "        data_last = input_data[-1:,:,:].clone()\n",
        "        data_last[0,0,1] = prediction.item()\n",
        "\n",
        "        input_data = torch.cat((input_data[1:,:,:],data_last),axis=0)\n",
        "\n",
        "      \n",
        "      total_prediction = torch.tensor(all_predictions).to(device)\n",
        "      \n",
        "      timestamps = torch.from_numpy(np.arange(date) + starting_date + 1).to(device).view(date,1)\n",
        "      \n",
        "      prediction_with_time = torch.cat([timestamps,total_prediction.view(date,1)],axis=1)\n",
        "      \n",
        "      predictions.append(prediction_with_time.tolist())\n",
        "      loss = criterion(torch.squeeze(target)[i:i+date,1],total_prediction)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "    \n",
        "  return epoch_loss/num_tries, np.array(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Y9vFqrs4Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_plot(prediction_list, target_list):\n",
        "  fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "  ax = []\n",
        "  for i in range(7):\n",
        "    ax.append(fig.add_subplot(7,1,i+1)) \n",
        "\n",
        "  step = 100\n",
        "  for i in range(1,8):\n",
        "    start = (i-1) * step\n",
        "\n",
        "    if i == 7: end = prediction_list.shape[0]\n",
        "    else: end = i * step\n",
        "\n",
        "  # try:\n",
        "    ax[i-1].plot(target_list[0:,0][start:end],target_list[0:,1][start:end])\n",
        "    ax[i-1].plot(prediction_list[:,0,0][start:end],prediction_list[:,0,1][start:end])\n",
        "    for j in range(start, end):\n",
        "      if j%foresee_date == 0:\n",
        "        ax[i-1].plot(prediction_list[:,:,0][j],prediction_list[:,:,1][j], color = 'b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDX_mXzF5lOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_plot_val(prediction_list, target_list):\n",
        "  fig = plt.figure(figsize=(20, 5))\n",
        "\n",
        "  ax = []\n",
        "  distribution = 2\n",
        "  for i in range(distribution):\n",
        "    ax.append(fig.add_subplot(distribution,1,i+1)) \n",
        "\n",
        "  step = 100\n",
        "  for i in range(1,distribution+1):\n",
        "    start = (i-1) * step\n",
        "\n",
        "    if i == distribution: end = prediction_list.shape[0]\n",
        "    else: end = i * step\n",
        "  # try:\n",
        "    ax[i-1].plot(target_list[0:,0][start:end],target_list[0:,1][start:end])\n",
        "    ax[i-1].plot(prediction_list[:,0,0][start:end],prediction_list[:,0,1][start:end])\n",
        "    for j in range(start, end):\n",
        "      if j%foresee_date == 0:\n",
        "        ax[i-1].plot(prediction_list[:,:,0][j],prediction_list[:,:,1][j], color = 'b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-quAwSyfsqe",
        "colab_type": "text"
      },
      "source": [
        "**hyper parameter**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k9Oi22xfqm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lr = 0.0005\n",
        "# time_steps = 20\n",
        "# epoch = 50\n",
        "# batch_size = 5\n",
        "# dropout_rate = 0.3\n",
        "# num_layers = 2\n",
        "# input_size = data_np.shape[1] #open close high low volume\n",
        "# #hidden1 = 100\n",
        "# hidden = 25\n",
        "# #fc = 15\n",
        "\n",
        "# foresee_date = 5\n",
        "# shuffle = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6mP6pqzgFKZ",
        "colab_type": "text"
      },
      "source": [
        "# **create model**\n",
        "지정 디렉터리에 같은 학습모델이 있을 경우, 그 모델을 불러와서 학습\n",
        "\n",
        "1.   지정 디렉터리에 같은 학습모델이 있을 경우, 그 모델을 불러와서 학습\n",
        "2.   마운트 필수\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX_UXoojRrfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def call_model(model, num_layer, hidden_layer):\n",
        "\n",
        "  path_dir = \"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/\"\n",
        "  pretrained_model_list = os.listdir(path_dir)\n",
        "  pretrained_model_list.sort()   #가장 loss가 낮은 모델을 부르기 위해 정렬 #저장양식 model_name + \"-loss_\"+str(int(loss*1000)) ex LSTM_sequential_loss_1 #모델/loss 구분 \"-\"(하이푼)\n",
        "  i = 0\n",
        "  model_state = model.state_dict()\n",
        "  pre_train_loss = 1\n",
        "  for trained_model in pretrained_model_list:\n",
        "    i+=1\n",
        "    if str(model) == trained_model.split(\"-\")[0] and num_layer == int(trained_model.split(\"-\")[1]) and hidden_layer == int(trained_model.split(\"-\")[2]) and str(input_size)==trained_model.split(\"-\")[3]:\n",
        "      model_state = torch.load(path_dir+\"/\"+trained_model)[\"model_state\"]\n",
        "      #model.load_state_dict(torch.load(path_dir+\"/\"+trained_model)[\"model_state\"])\n",
        "      pre_train_loss = torch.load(path_dir+\"/\"+trained_model)[\"loss\"]\n",
        "      lr =torch.load(path_dir+\"/\"+trained_model)[\"lr\"]\n",
        "      optimzier = torch.load(path_dir+\"/\"+trained_model)[\"optimizer\"]\n",
        "      print(\"불러온 모델\",trained_model, \"pre_train_loss: \",pre_train_loss)   \n",
        "      break\n",
        "    if i == len(pretrained_model_list):\n",
        "      print(\"저장된 같은 모델이 없습니다\")\n",
        "  return model_state, pre_train_loss\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tg2u0H8GBsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_preprocessing(data_norm,time_steps, foresee_date):\n",
        "  slice_point = 800\n",
        "  data_train_np = data_norm[:slice_point,:]\n",
        "  data_val_np = data_norm[slice_point:,:]\n",
        "  data_train_tensor = torch.from_numpy(np.expand_dims(data_train_np, axis=1)).to(device)\n",
        "  data_val_tensor = torch.from_numpy(np.expand_dims(data_val_np, axis=1)).to(device)\n",
        "\n",
        "  target_train_np = data_train_np[time_steps:,[0,2]]\n",
        "\n",
        "  target_train_tensor = torch.from_numpy(np.expand_dims(target_train_np, axis=0)).to(device)\n",
        "  target_val_np = data_val_np[time_steps:,[0,2]]\n",
        "  target_val_tensor = torch.from_numpy(np.expand_dims(target_val_np, axis=0)).to(device)\n",
        "\n",
        "  train_batches = []\n",
        "\n",
        "  for i in range((slice_point - time_steps - (foresee_date - 1)) // batch_size):\n",
        "    data_batch = []\n",
        "    train_batch = []\n",
        "    for b in range(batch_size):\n",
        "      data_batch.append(data_train_tensor[i*batch_size + b:i*batch_size + b + time_steps,:,:])\n",
        "      train_batch.append(target_train_tensor[:,i*batch_size + b:i*batch_size + b + foresee_date])\n",
        "      \n",
        "    train_batches.append((torch.cat(data_batch,axis=1),torch.cat(train_batch,axis=0)))\n",
        "\n",
        "  return data_train_np, data_val_np, target_train_np, target_val_np, train_batches ,data_batch, data_val_tensor, data_train_tensor,target_train_tensor,target_val_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gg0e4Ho01Hic"
      },
      "source": [
        "**hyper parameter**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv08M19q1Ieo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0005\n",
        "time_steps = 20\n",
        "epoch = 50\n",
        "batch_size = 5\n",
        "dropout_rate = 0.3\n",
        "num_layers = 2\n",
        "input_size = data_np.shape[1] #open close high low volume\n",
        "#hidden1 = 100\n",
        "hidden = 25\n",
        "#fc = 15\n",
        "\n",
        "foresee_date = 5\n",
        "shuffle = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VtBWgQU3sA2",
        "colab_type": "text"
      },
      "source": [
        "# **Model training**\n",
        "이전 모델의 loss보다 낮은 loss를 기록할 경우 자동 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3lpr12OMShP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_point = 1       ##mamximum = 5040             ################여기서 포인트 설정#########################\n",
        "count = 0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6HSYrWmlklC",
        "colab_type": "code",
        "outputId": "a36fcb97-9f6e-4135-9399-56632494255f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir = \"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_size = data_np.shape[1]\n",
        "pre_train_loss = 1\n",
        "\n",
        "lr_list = [lr, lr/3, lr/5]\n",
        "hidden_list = list(range(10,50,5))\n",
        "num_layer_list = list(range(2,4))\n",
        "foresee_date_list = list(range(1,6))\n",
        "time_step_list = list(range(10,31))\n",
        "\n",
        "\n",
        "\n",
        "# optimizer_list = [optim.Adam(model.parameters(), lr = lr), optim.SGD(model.parameters(), lr = lr)]\n",
        "\n",
        "                     \n",
        "#try:\n",
        "for num_layer2 in num_layer_list:\n",
        "  for h_layer2 in hidden_list:\n",
        "    model = LSTM_sequential(input_size, hidden, dropout_rate, num_layer2)\n",
        "    model = model.to(device)\n",
        "    model = model.double()\n",
        "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    criterion = criterion.to(device)\n",
        "    model_state, pre_train_loss =  call_model(model, num_layer2, h_layer2)\n",
        "    model.load_state_dict(model_state)\n",
        "    for time_step2 in time_step_list:\n",
        "      for foresee_date2 in foresee_date_list:\n",
        "        data_train_np, data_val_np, target_train_np, target_val_np, train_batches ,data_batch, data_val_tensor, data_train_tensor,target_train_tensor,target_val_tensor = data_preprocessing(data_norm, time_step2,foresee_date2)\n",
        "        for lr2 in lr_list:\n",
        "          count +=1\n",
        "          #print(count)\n",
        "          if count < save_point: continue         #저장지점까지 continue\n",
        "\n",
        "          # if lr < lr2 and lr != lr_list[-1]:      #만약 불러온 모델의 lr이 더 낮을경우 그 lr에 대한 학습은 건너뜀, 제일 작은 lr경우는 학습함\n",
        "          #   continue\n",
        "          print(\"lr:\",lr2, \"foresee_date:\",foresee_date2, \"h_layer:\",h_layer2, \"num_layer:\",num_layer2)\n",
        "          if shuffle:\n",
        "            random.shuffle(train_batches)\n",
        "            for ep in range(100):\n",
        "              optimizer = optim.Adam(model.parameters(), lr = lr2)\n",
        "              start_time = time.time()\n",
        "              train_loss = train(time_step2, foresee_date2, train_batches, model, optimizer, criterion)\n",
        "              end_time = time.time()\n",
        "              if ep%10 == 0:\n",
        "                print(train_loss)\n",
        "                print(end_time - start_time)\n",
        "                if train_loss < pre_train_loss and train_loss < 0.003:      #이전보다 loss가 낮으면 저장함.\n",
        "                  pre_train_loss = train_loss           #제일 낮은 loss 갱신\n",
        "                  if not os.path.exists(dir):\n",
        "                    os.makedirs(dir)          #dir가 없으면 만들어서 저장\n",
        "                  save_dict = {\"model_state\":model.state_dict(),\n",
        "                                \"loss\":train_loss,\n",
        "                                \"lr\": lr2,\n",
        "                                \"optimizer\": optimizer,\n",
        "                                \"hidden_layer\": h_layer2,\n",
        "                                \"num_layers\" : num_layer2,\n",
        "                                \"time_step\":time_step2,\n",
        "                                \"foresee_date\":foresee_date2}\n",
        "                  model_name = dir+str(model)+\"-\"+str(num_layer2)+'-'+str(h_layer2)+\"-\"+str(input_size)+\"-\"+'loss_'+str(int(train_loss*1000))+\".pt\"         #여러명이 돌릴경우 직관성을 위해 filename에 loss도 포함\n",
        "                  torch.save(save_dict,model_name)\n",
        "                  print(\"save\",model_name)\n",
        "                  loss_train, predictions_train = evaluate(time_step2, foresee_date2, data_train_tensor, target_train_tensor, model, criterion)\n",
        "                  view_plot(predictions_train, target_train_np)\n",
        "                  loss_val, predictions_val = evaluate(time_step2,foresee_date2, data_val_tensor, target_val_tensor, model, criterion)\n",
        "                  view_plot_val(predictions_val, target_val_np)\n",
        "# except Exception as inst:\n",
        "#   print(inst)\n",
        "#   print(\"your check point:\", count)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "저장된 같은 모델이 없습니다\n",
            "lr: 0.0005 foresee_date: 1 h_layer: 10 num_layer: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.08451591775773579\n",
            "0.9495666027069092\n",
            "0.005056009680575861\n",
            "0.8791296482086182\n",
            "0.004691906640557633\n",
            "0.8812606334686279\n",
            "0.0033295171594597307\n",
            "0.8420422077178955\n",
            "0.0032613583420225125\n",
            "0.8996655941009521\n",
            "0.003618336912854301\n",
            "0.8721659183502197\n",
            "0.0026618478907923545\n",
            "0.8702602386474609\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-5-loss_2.pt\n",
            "0.0029284364888942016\n",
            "0.889359712600708\n",
            "0.0027952984747376865\n",
            "0.906301736831665\n",
            "0.0031440414172032457\n",
            "0.9389841556549072\n",
            "lr: 0.00016666666666666666 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.002352491712333265\n",
            "0.8932051658630371\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-5-loss_2.pt\n",
            "0.0025521312953342397\n",
            "0.8533859252929688\n",
            "0.002677131133889802\n",
            "0.9223597049713135\n",
            "0.002506725186535003\n",
            "0.9017705917358398\n",
            "0.002538595323245819\n",
            "0.8787312507629395\n",
            "0.0025528729588641863\n",
            "0.9632506370544434\n",
            "0.002450317663328371\n",
            "0.9986867904663086\n",
            "0.0026773607373626533\n",
            "1.0077826976776123\n",
            "0.002613806772881378\n",
            "0.920767068862915\n",
            "0.002298842425990379\n",
            "0.8660843372344971\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-5-loss_2.pt\n",
            "lr: 0.0001 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.002531651257278556\n",
            "0.8826513290405273\n",
            "0.0024759350883429743\n",
            "0.9571068286895752\n",
            "0.0027235798220985727\n",
            "0.8838534355163574\n",
            "0.002652788902608726\n",
            "0.9019944667816162\n",
            "0.002322778975413757\n",
            "0.902099609375\n",
            "0.002417791396617739\n",
            "0.8741247653961182\n",
            "0.002474087609159887\n",
            "0.9022574424743652\n",
            "0.0025556406209575233\n",
            "0.920297384262085\n",
            "0.002650891895734737\n",
            "0.9877097606658936\n",
            "0.002521319550048982\n",
            "0.8850061893463135\n",
            "lr: 0.0005 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.002403441451694816\n",
            "1.3554043769836426\n",
            "0.0025421309777250546\n",
            "1.3959088325500488\n",
            "0.0025392214557205385\n",
            "1.40175199508667\n",
            "0.0024837885408170884\n",
            "1.364351749420166\n",
            "0.0026010687469754444\n",
            "1.3335106372833252\n",
            "0.0027427259579979853\n",
            "1.3361804485321045\n",
            "0.0025479837535867544\n",
            "1.3944838047027588\n",
            "0.0027334795060126225\n",
            "1.3516552448272705\n",
            "0.002736860778987677\n",
            "1.3506300449371338\n",
            "0.0026836245969718954\n",
            "1.3593580722808838\n",
            "lr: 0.00016666666666666666 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.002455634000912496\n",
            "1.500108242034912\n",
            "0.0024047867964367277\n",
            "1.3579063415527344\n",
            "0.002376756072608916\n",
            "1.3623759746551514\n",
            "0.002519221589297958\n",
            "1.3447246551513672\n",
            "0.0022026555418789657\n",
            "1.3750650882720947\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-5-loss_2.pt\n",
            "0.002352736804990555\n",
            "1.3526301383972168\n",
            "0.002416450864567123\n",
            "1.4041335582733154\n",
            "0.002452576298088783\n",
            "1.4229686260223389\n",
            "0.0023083637485476465\n",
            "1.4067323207855225\n",
            "0.0024381008310348827\n",
            "1.3751869201660156\n",
            "lr: 0.0001 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.0025053108134818532\n",
            "1.4342005252838135\n",
            "0.002339347974618614\n",
            "1.3254122734069824\n",
            "0.0022347097843385894\n",
            "1.349165678024292\n",
            "0.002345773610116233\n",
            "1.3464529514312744\n",
            "0.0021462005731404748\n",
            "1.4282310009002686\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-5-loss_2.pt\n",
            "0.0024323674167111807\n",
            "1.4315781593322754\n",
            "0.0021893441922886414\n",
            "1.3107991218566895\n",
            "0.002327357618989636\n",
            "1.3046467304229736\n",
            "0.0022681902383440457\n",
            "1.4347219467163086\n",
            "0.0022654604164405235\n",
            "1.4004325866699219\n",
            "lr: 0.0005 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.002645148981921397\n",
            "1.8357079029083252\n",
            "0.0027467514393972737\n",
            "1.8276991844177246\n",
            "0.0026783055883831896\n",
            "1.833143711090088\n",
            "0.0027376115993412446\n",
            "2.0331408977508545\n",
            "0.00248911063327912\n",
            "1.8422205448150635\n",
            "0.0026632767485332033\n",
            "1.7728288173675537\n",
            "0.0026802957542000727\n",
            "2.0052247047424316\n",
            "0.0025215568426728437\n",
            "1.8925063610076904\n",
            "0.0025885662366913424\n",
            "1.8741674423217773\n",
            "0.0027306459660729246\n",
            "1.8045217990875244\n",
            "lr: 0.00016666666666666666 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.002559314771557965\n",
            "1.8371264934539795\n",
            "0.002617100852238999\n",
            "1.8103723526000977\n",
            "0.002380731231507295\n",
            "1.7728667259216309\n",
            "0.002520659948581775\n",
            "1.8485357761383057\n",
            "0.0024837058216223783\n",
            "1.903066635131836\n",
            "0.002493464633234273\n",
            "1.7669074535369873\n",
            "0.002583850923446294\n",
            "1.8241698741912842\n",
            "0.002461660278388106\n",
            "1.8015639781951904\n",
            "0.0024862931546143297\n",
            "1.8730831146240234\n",
            "0.0024471478902973296\n",
            "1.8840997219085693\n",
            "lr: 0.0001 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.002332707290470553\n",
            "1.9078798294067383\n",
            "0.002385443467829634\n",
            "1.8516483306884766\n",
            "0.0023408236977129214\n",
            "2.007035970687866\n",
            "0.0023861945014010196\n",
            "1.8226730823516846\n",
            "0.0024495464712857374\n",
            "1.826267957687378\n",
            "0.0022884987752108846\n",
            "1.8452215194702148\n",
            "0.002615528631591843\n",
            "1.8247671127319336\n",
            "0.002491542078616849\n",
            "1.8373394012451172\n",
            "0.0024344358840971787\n",
            "1.8324403762817383\n",
            "0.0023779175793066953\n",
            "1.8917362689971924\n",
            "lr: 0.0005 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.0026186174033150894\n",
            "2.25527286529541\n",
            "0.0026130789056173264\n",
            "2.4161536693573\n",
            "0.0027314669007090942\n",
            "2.40915584564209\n",
            "0.002669913460897674\n",
            "2.3180673122406006\n",
            "0.0026205999252381044\n",
            "2.396662473678589\n",
            "0.00272282942755356\n",
            "2.361050605773926\n",
            "0.00272797301830993\n",
            "2.3300626277923584\n",
            "0.00265239113742559\n",
            "2.3897979259490967\n",
            "0.0026165859602812276\n",
            "2.476776123046875\n",
            "0.002757921198744503\n",
            "2.2732386589050293\n",
            "lr: 0.00016666666666666666 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.0025006638076761085\n",
            "2.3787806034088135\n",
            "0.0026130182382770764\n",
            "2.3719091415405273\n",
            "0.0025258053465102037\n",
            "2.572265625\n",
            "0.002581578822750837\n",
            "2.330780506134033\n",
            "0.002561133937394927\n",
            "2.243685483932495\n",
            "0.002490101759660792\n",
            "2.209320306777954\n",
            "0.002560274216892027\n",
            "2.4874651432037354\n",
            "0.0024801915849842083\n",
            "2.5027337074279785\n",
            "0.0024681691616862695\n",
            "2.298783302307129\n",
            "0.002484351773756409\n",
            "2.4399919509887695\n",
            "lr: 0.0001 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.0024834280588827756\n",
            "2.2074079513549805\n",
            "0.002512727525556681\n",
            "2.2546300888061523\n",
            "0.002582648466732405\n",
            "2.285386085510254\n",
            "0.002674348241992707\n",
            "2.28981351852417\n",
            "0.002561267957153931\n",
            "2.29970121383667\n",
            "0.002527683935643436\n",
            "2.2980575561523438\n",
            "0.0025802915248860983\n",
            "2.3480772972106934\n",
            "0.0025995853257351014\n",
            "2.457582950592041\n",
            "0.0026128399440161778\n",
            "2.322390556335449\n",
            "0.002527201973683257\n",
            "2.3072640895843506\n",
            "lr: 0.0005 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.0029129715809342177\n",
            "2.840487003326416\n",
            "0.0026687858473971194\n",
            "2.9316303730010986\n",
            "0.0028025496598637002\n",
            "2.9455928802490234\n",
            "0.002863142939570344\n",
            "2.7502968311309814\n",
            "0.002749215781572121\n",
            "2.765681028366089\n",
            "0.002679340613904424\n",
            "2.8749008178710938\n",
            "0.002805335596979243\n",
            "2.715585231781006\n",
            "0.002718224011805001\n",
            "2.829630136489868\n",
            "0.002612276152592754\n",
            "2.7254624366760254\n",
            "0.0026866059905673715\n",
            "2.778254508972168\n",
            "lr: 0.00016666666666666666 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.0026836309105366216\n",
            "2.870875120162964\n",
            "0.0026188519350753368\n",
            "2.832880973815918\n",
            "0.0025907143646526575\n",
            "2.7105746269226074\n",
            "0.002670579377928469\n",
            "2.76275372505188\n",
            "0.0025801392294702123\n",
            "2.8097493648529053\n",
            "0.002618903774639487\n",
            "2.953704595565796\n",
            "0.0025750487909590837\n",
            "2.773052215576172\n",
            "0.0025484240644762972\n",
            "3.021223783493042\n",
            "0.0026760336286917024\n",
            "2.773843288421631\n",
            "0.0026565624465742883\n",
            "2.903418779373169\n",
            "lr: 0.0001 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.002628431639811001\n",
            "2.7311999797821045\n",
            "0.0024778748249681833\n",
            "2.788959264755249\n",
            "0.002496701537982862\n",
            "2.7487542629241943\n",
            "0.0027089298206028037\n",
            "2.701594114303589\n",
            "0.002520914590863384\n",
            "2.850168228149414\n",
            "0.0025636251756113427\n",
            "2.8980231285095215\n",
            "0.0025293626587556063\n",
            "2.803415298461914\n",
            "0.0026423731373370414\n",
            "2.9918487071990967\n",
            "0.0026513030935857483\n",
            "2.8167619705200195\n",
            "0.002635598211949518\n",
            "2.8536596298217773\n",
            "lr: 0.0005 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.0024811398176300295\n",
            "0.8907172679901123\n",
            "0.0025402932817427328\n",
            "0.9130687713623047\n",
            "0.002500217681067963\n",
            "0.8655939102172852\n",
            "0.002360035357747697\n",
            "0.9009943008422852\n",
            "0.002427599043889417\n",
            "0.8640785217285156\n",
            "0.002376251047171779\n",
            "0.9176506996154785\n",
            "0.0025009576507690036\n",
            "0.9087276458740234\n",
            "0.0026991620383806157\n",
            "0.8803536891937256\n",
            "0.002584503025714391\n",
            "0.8756711483001709\n",
            "0.0022775601620190654\n",
            "0.8731021881103516\n",
            "lr: 0.00016666666666666666 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.0022350382967349985\n",
            "1.0750243663787842\n",
            "0.0021667794158604235\n",
            "0.8890047073364258\n",
            "0.0022902850892628454\n",
            "0.8406381607055664\n",
            "0.0023035726821884444\n",
            "0.8607394695281982\n",
            "0.002541655850309204\n",
            "0.9250686168670654\n",
            "0.0022206857717140165\n",
            "0.9269716739654541\n",
            "0.0019916779475138975\n",
            "0.9117302894592285\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-5-loss_1.pt\n",
            "0.0021433964167506237\n",
            "0.9122228622436523\n",
            "0.002185177079452167\n",
            "0.8927888870239258\n",
            "0.0022170221258710947\n",
            "0.909600019454956\n",
            "lr: 0.0001 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.0022168758238219556\n",
            "0.9024434089660645\n",
            "0.0021676921123385817\n",
            "0.9035789966583252\n",
            "0.0022246653747498247\n",
            "0.8582162857055664\n",
            "0.002152970915108227\n",
            "0.9546051025390625\n",
            "0.002252415849133045\n",
            "0.9565024375915527\n",
            "0.002149833696346637\n",
            "0.8977146148681641\n",
            "0.002355146298220667\n",
            "0.8823184967041016\n",
            "0.0020195628893120467\n",
            "0.8967609405517578\n",
            "0.0024619629710899023\n",
            "0.8853604793548584\n",
            "0.0022841448483457132\n",
            "1.023254632949829\n",
            "lr: 0.0005 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.002213123290194208\n",
            "1.3839199542999268\n",
            "0.0025098646734649553\n",
            "1.3307981491088867\n",
            "0.0025443171369310593\n",
            "1.3416070938110352\n",
            "0.002154159482914388\n",
            "1.3581047058105469\n",
            "0.002369058334815324\n",
            "1.3505768775939941\n",
            "0.0020582768241901766\n",
            "1.3262159824371338\n",
            "0.0023356415537977276\n",
            "1.531198263168335\n",
            "0.0023508955779436972\n",
            "1.3599739074707031\n",
            "0.0021126610651770773\n",
            "1.3648579120635986\n",
            "0.0022400196409286264\n",
            "1.353783369064331\n",
            "lr: 0.00016666666666666666 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.002342802116464561\n",
            "1.4195218086242676\n",
            "0.002185733764750773\n",
            "1.3719356060028076\n",
            "0.0022452544629556785\n",
            "1.439762830734253\n",
            "0.002057238229423825\n",
            "1.3537509441375732\n",
            "0.0021110202554923923\n",
            "1.4405937194824219\n",
            "0.0020981590650295903\n",
            "1.5392460823059082\n",
            "0.0021683016075049618\n",
            "1.5437874794006348\n",
            "0.0020383329727032373\n",
            "1.3412086963653564\n",
            "0.002118165251037636\n",
            "1.4303066730499268\n",
            "0.0021663614511746965\n",
            "1.370584487915039\n",
            "lr: 0.0001 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.0020962546944057153\n",
            "1.4141864776611328\n",
            "0.002114323642644924\n",
            "1.3675193786621094\n",
            "0.002288784861222556\n",
            "1.363572120666504\n",
            "0.0021592442754314843\n",
            "1.385333776473999\n",
            "0.0022417105145830763\n",
            "1.3794667720794678\n",
            "0.0019446112222859557\n",
            "1.376481294631958\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-5-loss_1.pt\n",
            "0.0022601361188983394\n",
            "1.3660862445831299\n",
            "0.0022257975841445247\n",
            "1.4147813320159912\n",
            "0.002097617900652448\n",
            "1.4701364040374756\n",
            "0.0019617956311643414\n",
            "1.3604073524475098\n",
            "lr: 0.0005 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.0022891116016438475\n",
            "2.222914218902588\n",
            "0.002359110134272009\n",
            "1.9209296703338623\n",
            "0.0022677884449411596\n",
            "1.8308806419372559\n",
            "0.002256230004222145\n",
            "1.8835968971252441\n",
            "0.002224721059040235\n",
            "1.931095838546753\n",
            "0.0022849157201472216\n",
            "1.8506696224212646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpqt2stv2h8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#direc = \"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/model1.py\"\n",
        "#torch.save(model.state_dict(), direc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8z5E51e4VyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model2 = LSTM_sequential(input_size, hidden, dropout_rate).to(device).double()\n",
        "#model2.load_state_dict(torch.load(\"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/model1.py\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxmCwkA-Zp4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "# plt.plot(target_train_np[:,1])\n",
        "# plt.plot(predictions_train[:,0,1])\n",
        "view_plot(predictions_train, target_train_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beElDM1fM916",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "#plt.figure(figsize=(100, 5))\n",
        "\n",
        "view_plot(predictions_train, target_train_np)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8IsWxsWbCf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(target_train_np[d - 1:,1])\n",
        "#print(predictions_train[:,d-1,1])\n",
        "#print(pre_with_time)\n",
        "# print(predictions_train[:,:,1][:100])\n",
        "# print(predictions_train[:,:,0][0])\n",
        "#print(predictions_train[:2,:,1])\n",
        "# print(predictions_train.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jSKakYB2N6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps,foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "view_plot(predictions_train, target_train_np)\n",
        "# plt.plot(target_train_np[d - 1:,1])\n",
        "# plt.plot(predictions_train[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY5lFdlI2Iaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps,foresee_date, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "\n",
        "view_plot_val(predictions_val, target_val_np)\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn3Queky5Yyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx0r5h1H2Pzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps,foresee_date, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "view_plot_val(predictions_val, target_val_np)\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Ey9k02og27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = lr/3)\n",
        "\n",
        "for ep in range(200):\n",
        "  start_time = time.time()\n",
        "  if shuffle:\n",
        "    random.shuffle(train_batches)\n",
        "  train_loss = train(time_steps,foresee_date, train_batches, model, optimizer, criterion)\n",
        "  end_time = time.time()\n",
        "  if ep%50 == 0:\n",
        "    print(train_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap9DL0vS2nE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps,foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "view_plot(predictions_train, target_train_np)\n",
        "# plt.plot(target_train_np[d - 1:,1])\n",
        "# plt.plot(predictions_train[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edip56o82m-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps,foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "view_plot(predictions_train, target_train_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1hNPHJ42m2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps,foresee_date, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "view_plot_val(predictions_val, target_val_np)\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-SF9ORn2mtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps,foresee_date, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "view_plot_val(predictions_val, target_val_np)\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNzDTD9fv0Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = lr/5)\n",
        "\n",
        "for ep in range(200):\n",
        "  start_time = time.time()\n",
        "  train_loss = train(time_steps,foresee_date, train_batches, model, optimizer, criterion)\n",
        "  end_time = time.time()\n",
        "  if ep%50 == 0:\n",
        "    print(train_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isgt8i_gWWth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps,foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "\n",
        "# print(predictions_train.shape)\n",
        "# print(target_train_np.shape)\n",
        "\n",
        "# plt.plot(target_train_np[d - 1:,1][300:500])\n",
        "# plt.plot(predictions_train[:,d - 1,1][300:500])\n",
        "\n",
        "# print(target_train_np[d - 1,0])\n",
        "# print(predictions_train[0,d-1,0])\n",
        "view_plot(predictions_train, target_train_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_D50oC1d2PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps, foresee_date,data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "# d = 5\n",
        "\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])\n",
        "view_plot_val(predictions_val, target_val_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1GRFauTG8w0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw6T2edFzKP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}