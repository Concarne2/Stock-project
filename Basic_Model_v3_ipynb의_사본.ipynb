{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Model v3.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomYOON/Stock-project/blob/master/Basic_Model_v3_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0hF7M50RySa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCeNc93yecPR",
        "colab_type": "text"
      },
      "source": [
        "# **Mount your drive**\n",
        "본인의 구글 드라이브와 Colab을 연동합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIs8LcpQ2NkM",
        "colab_type": "code",
        "outputId": "2da6977b-173f-4a42-a1c4-116ad56cffe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpbeiVKHV0KG",
        "colab_type": "code",
        "outputId": "58a2db7e-d350-4f6d-cdef-35e9023e2ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#importing data from url\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/Concarne2/stock_data/master/DATA/sk%ED%95%98%EC%9D%B4%EB%8B%89%EC%8A%A4(%EC%88%98%EC%A0%95).csv\"\n",
        "csv_df=pd.read_csv(url)\n",
        "\n",
        "#  0     1    2    3     4      5    6    7\n",
        "# year,month,day,close,volume,start,high,low\n",
        "\n",
        "\n",
        "csv_np_raw = csv_df.to_numpy()\n",
        "row,col = np.shape(csv_np_raw)\n",
        "\n",
        "for i in range(row):\n",
        "  for j in range(3,col):\n",
        "    csv_np_raw[i][j] = csv_np_raw[i][j].replace(\",\",\"\")\n",
        "\n",
        "full_data_np = np.flip(csv_np_raw.astype(int),axis=0)\n",
        "data_np = full_data_np[:,[5,3,6,7,4]]\n",
        "#data_np = full_data_np[:,[6,3,7,4]]\n",
        "\n",
        "print(data_np.shape)\n",
        "#plt.plot(data_np[:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(980, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VswRwOMSLPcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize data\n",
        "\n",
        "#data_min = np.min(data_np[:,1])\n",
        "#data_scale = np.max(data_np[:,1]) - np.min(data_np[:,1])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data_np)\n",
        "data_norm = scaler.transform(data_np)\n",
        "data_norm = np.insert(data_norm,0,np.arange(data_norm.shape[0]),axis=1)\n",
        "#data = torch.from_numpy(data_norm)\n",
        "#plt.plot(data_norm[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTKTvc8yn05A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoreBasicLSTM(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, output_size):\n",
        "    super().__init__()\n",
        "    self.date = output_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = output_size)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(inputs)\n",
        "    output = self.drop(hidden.squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXlAPYcri7LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoreBasicLSTM_timestamp_processing(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, output_size):\n",
        "    super().__init__()\n",
        "    self.date = output_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = output_size)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    input_without_timestamp = inputs[:,:,1:]\n",
        "    batch_size = inputs\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(input_without_timestamp)\n",
        "    output = self.drop(hidden.squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    print(output.size())\n",
        "    output = output.view(self.date,1)\n",
        "    timestamps = torch.from_numpy(np.arange(self.date) + inputs[-1,:,0].item() + 1).view(self.date,1)\n",
        "    \n",
        "    return torch.cat([timestamps,output],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr-WEhdxZilr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_twolayer(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, output_size):\n",
        "    super().__init__()\n",
        "    self.date = output_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden, num_layers = 2, dropout = drop)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = output_size)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(inputs)\n",
        "    output = self.drop(hidden[1,:,:].squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QdItl4_aEga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_sequential(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, num_layer=1):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layer\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden,num_layers = self.num_layers, dropout = drop)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = 1)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(inputs)\n",
        "    output = self.drop(hidden[1,:,:].squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    \n",
        "    return output\n",
        "\n",
        "#str 변환시 함수 이름이 출력되게함\n",
        "  def __str__(self):\n",
        "    return str(LSTM_sequential).split(\".\")[1][:-2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNUIr_wMZNK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(time_steps, date, data_target_batches, model, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  #prediction_list=[]\n",
        "  batch_amount = len(data_target_batches)\n",
        "  batch_size = list(data_target_batches[0][0].size())[1]\n",
        "  model.train()\n",
        "  \n",
        "  for data, target in data_target_batches:\n",
        "    \n",
        "    assert target[0,0,0].item() == (data[-1,0,0].item() + 1)\n",
        "    \n",
        "    optimizer.zero_grad()   \n",
        "    \n",
        "    data_without_timestamp = data[:,:,1:].clone()\n",
        "\n",
        "    all_predictions = []\n",
        "    \n",
        "    for d in range(date):\n",
        "      prediction_batch = model(data_without_timestamp)\n",
        "      all_predictions.append(prediction_batch)\n",
        "      data_last = data_without_timestamp[-1:,:,:].clone()\n",
        "      for b in range(batch_size):\n",
        "        data_last[0,b,1] = prediction_batch[b].item()  \n",
        "\n",
        "\n",
        "      data_without_timestamp = torch.cat((data_without_timestamp[1:,:,:],data_last),axis=0)\n",
        "\n",
        "    target_without_timestamp = torch.squeeze(target[:,:,1])\n",
        "    loss = criterion(target_without_timestamp, torch.cat(all_predictions,axis=1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / batch_amount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8SP9jUcowZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(time_steps, date, data, target, model, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  predictions=[]\n",
        "  \n",
        "  model.eval()\n",
        "  num_tries = list(target.size())[1] - (date - 1)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i in range(num_tries):\n",
        "\n",
        "      starting_date = data[i:i+time_steps,:,:][-1,0,0].item()\n",
        "\n",
        "      input_data = data[i:i+time_steps,:,1:]\n",
        "\n",
        "      all_predictions = []\n",
        "\n",
        "      for d in range(date):\n",
        "        prediction = model(input_data)\n",
        "        all_predictions.append(prediction)\n",
        "        data_last = input_data[-1:,:,:].clone()\n",
        "        data_last[0,0,1] = prediction.item()\n",
        "\n",
        "        input_data = torch.cat((input_data[1:,:,:],data_last),axis=0)\n",
        "\n",
        "      \n",
        "      total_prediction = torch.tensor(all_predictions).to(device)\n",
        "      \n",
        "      timestamps = torch.from_numpy(np.arange(date) + starting_date + 1).to(device).view(date,1)\n",
        "      \n",
        "      prediction_with_time = torch.cat([timestamps,total_prediction.view(date,1)],axis=1)\n",
        "      \n",
        "      predictions.append(prediction_with_time.tolist())\n",
        "      loss = criterion(torch.squeeze(target)[i:i+date,1],total_prediction)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "    \n",
        "  return epoch_loss/num_tries, np.array(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Y9vFqrs4Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_plot(prediction_list, target_list):\n",
        "  fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "  ax = []\n",
        "  for i in range(7):\n",
        "    ax.append(fig.add_subplot(7,1,i+1)) \n",
        "\n",
        "  step = 100\n",
        "  for i in range(1,8):\n",
        "    start = (i-1) * step\n",
        "\n",
        "    if i == 7: end = prediction_list.shape[0]\n",
        "    else: end = i * step\n",
        "\n",
        "  # try:\n",
        "    ax[i-1].plot(target_list[0:,0][start:end],target_list[0:,1][start:end])\n",
        "    ax[i-1].plot(prediction_list[:,0,0][start:end],prediction_list[:,0,1][start:end])\n",
        "    for j in range(start, end):\n",
        "      if j%foresee_date == 0:\n",
        "        ax[i-1].plot(prediction_list[:,:,0][j],prediction_list[:,:,1][j], color = 'b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDX_mXzF5lOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_plot_val(prediction_list, target_list):\n",
        "  fig = plt.figure(figsize=(20, 5))\n",
        "\n",
        "  ax = []\n",
        "  distribution = 2\n",
        "  for i in range(distribution):\n",
        "    ax.append(fig.add_subplot(distribution,1,i+1)) \n",
        "\n",
        "  step = 100\n",
        "  for i in range(1,distribution+1):\n",
        "    start = (i-1) * step\n",
        "\n",
        "    if i == distribution: end = prediction_list.shape[0]\n",
        "    else: end = i * step\n",
        "  # try:\n",
        "    ax[i-1].plot(target_list[0:,0][start:end],target_list[0:,1][start:end])\n",
        "    ax[i-1].plot(prediction_list[:,0,0][start:end],prediction_list[:,0,1][start:end])\n",
        "    for j in range(start, end):\n",
        "      if j%foresee_date == 0:\n",
        "        ax[i-1].plot(prediction_list[:,:,0][j],prediction_list[:,:,1][j], color = 'b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-quAwSyfsqe",
        "colab_type": "text"
      },
      "source": [
        "**hyper parameter**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k9Oi22xfqm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0005\n",
        "time_steps = 20\n",
        "epoch = 50\n",
        "batch_size = 5\n",
        "dropout_rate = 0.3\n",
        "num_layers = 2\n",
        "input_size = data_np.shape[1] #open close high low volume\n",
        "#hidden1 = 100\n",
        "hidden = 25\n",
        "#fc = 15\n",
        "\n",
        "foresee_date = 5\n",
        "shuffle = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6mP6pqzgFKZ",
        "colab_type": "text"
      },
      "source": [
        "# **create model**\n",
        "지정 디렉터리에 같은 학습모델이 있을 경우, 그 모델을 불러와서 학습\n",
        "\n",
        "1.   지정 디렉터리에 같은 학습모델이 있을 경우, 그 모델을 불러와서 학습\n",
        "2.   마운트 필수\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYEunrT72bYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def call_model(model):\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX_UXoojRrfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_list = [LSTM_sequential]  #여기다가 만든 모델 넣어서 자동학습 가능하게\n",
        "\n",
        "#model = BasicLSTM(input_size, hidden1, hidden2, fc)\n",
        "#model = BasicLSTM(input_size, hidden, fc)\n",
        "#model = MoreBasicLSTM(input_size, hidden, dropout_rate, foresee_date)\n",
        "#model = LSTM_twolayer(input_size, hidden, dropout_rate, foresee_date)\n",
        "# model = model_list[0](input_size, hidden, dropout_rate, num_layers)\n",
        "# model = model.to(device)\n",
        "# model = model.double()\n",
        "\n",
        "\n",
        "\n",
        "path_dir = \"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/\"\n",
        "\n",
        "\n",
        "#optimizer = optim.SGD(model.parameters(), lr = lr)\n",
        "# optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "# #criterion = nn.L1Loss()\n",
        "# criterion = nn.MSELoss()\n",
        "# criterion = criterion.to(device)\n",
        "\n",
        "\n",
        "pre_train_loss = 1\n",
        "\n",
        "# pretrained_model_list = os.listdir(path_dir)\n",
        "# pretrained_model_list.sort()   #가장 loss가 낮은 모델을 부르기 위해 정렬 #저장양식 model_name + \"-loss_\"+str(int(loss*1000)) ex LSTM_sequential_loss_1 #모델/loss 구분 \"-\"(하이푼)\n",
        "# print(pretrained_model_list)\n",
        "# i = 0\n",
        "# for trained_model in pretrained_model_list:\n",
        "#   i+=1\n",
        "#   #print(trained_model.split(\"-\")[0])\n",
        "#   if str(model) == trained_model.split(\"-\")[0] :            #저장된 모델이 지금 부르는 모델이랑 같은모델일 경우 state를 불러옴\n",
        "#     model.load_state_dict(torch.load(path_dir+\"/\"+trained_model)[\"model_state\"])\n",
        "#     pre_train_loss = torch.load(path_dir+\"/\"+trained_model)[\"loss\"]\n",
        "#     lr =torch.load(path_dir+\"/\"+trained_model)[\"lr\"]\n",
        "#     optimzier = torch.load(path_dir+\"/\"+trained_model)[\"optimizer\"]\n",
        "#     print(\"불러온 모델\",trained_model)                            #저장 조건을 위해 저장 당시의 loss를 부르고, lr 역시 이전의 lr일 경우 건너뛰기 위해 저장후 불러옴\n",
        "#     #print(model.state_dict())\n",
        "#     break\n",
        "#   if i == len(pretrained_model_list)-1:\n",
        "#     print(\"저장된 같은 모델이 없습니다\")\n",
        "\n",
        "#######test\n",
        "# train_loss = 1\n",
        "# model_name = dir+str(model)+\"-\"+str(num_layers)+'-'+str(hidden)+\"-\"+'loss_'+str(int(train_loss*1000))+\".pt\"         #여러명이 돌릴경우 직관성을 위해 filename에 loss도 포함\n",
        "# torch.save(save_dict,model_name)  \n",
        "\n",
        "def call_model(model, num_layer, hidden_layer):\n",
        "\n",
        "  path_dir = \"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/\"\n",
        "  pretrained_model_list = os.listdir(path_dir)\n",
        "  pretrained_model_list.sort()   #가장 loss가 낮은 모델을 부르기 위해 정렬 #저장양식 model_name + \"-loss_\"+str(int(loss*1000)) ex LSTM_sequential_loss_1 #모델/loss 구분 \"-\"(하이푼)\n",
        "  i = 0\n",
        "  model_state = model.state_dict()\n",
        "  pre_train_loss = 1\n",
        "  for trained_model in pretrained_model_list:\n",
        "    i+=1\n",
        "    if str(model) == trained_model.split(\"-\")[0] and num_layer == int(trained_model.split(\"-\")[1]) and hidden_layer == int(trained_model.split(\"-\")[2]) :\n",
        "      model_state = torch.load(path_dir+\"/\"+trained_model)[\"model_state\"]\n",
        "      #model.load_state_dict(torch.load(path_dir+\"/\"+trained_model)[\"model_state\"])\n",
        "      pre_train_loss = torch.load(path_dir+\"/\"+trained_model)[\"loss\"]\n",
        "      lr =torch.load(path_dir+\"/\"+trained_model)[\"lr\"]\n",
        "      optimzier = torch.load(path_dir+\"/\"+trained_model)[\"optimizer\"]\n",
        "      print(\"불러온 모델\",trained_model, \"pre_train_loss: \",pre_train_loss)   \n",
        "      break\n",
        "    if i == len(pretrained_model_list):\n",
        "      print(\"저장된 같은 모델이 없습니다\")\n",
        "  return model_state, pre_train_loss\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLLwxNDXeCXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######test######\n",
        "# model_state , pre_train_loss = call_model(model, num_layers, hidden)\n",
        "# model.load_state_dict(model_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tg2u0H8GBsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_preprocessing(data_norm,time_steps, foresee_date):\n",
        "  slice_point = 800\n",
        "  data_train_np = data_norm[:slice_point,:]\n",
        "  data_val_np = data_norm[slice_point:,:]\n",
        "  data_train_tensor = torch.from_numpy(np.expand_dims(data_train_np, axis=1)).to(device)\n",
        "  data_val_tensor = torch.from_numpy(np.expand_dims(data_val_np, axis=1)).to(device)\n",
        "\n",
        "  target_train_np = data_train_np[time_steps:,[0,2]]\n",
        "\n",
        "  target_train_tensor = torch.from_numpy(np.expand_dims(target_train_np, axis=0)).to(device)\n",
        "  target_val_np = data_val_np[time_steps:,[0,2]]\n",
        "  target_val_tensor = torch.from_numpy(np.expand_dims(target_val_np, axis=0)).to(device)\n",
        "\n",
        "  train_batches = []\n",
        "\n",
        "  for i in range((slice_point - time_steps - (foresee_date - 1)) // batch_size):\n",
        "    data_batch = []\n",
        "    train_batch = []\n",
        "    for b in range(batch_size):\n",
        "      data_batch.append(data_train_tensor[i*batch_size + b:i*batch_size + b + time_steps,:,:])\n",
        "      train_batch.append(target_train_tensor[:,i*batch_size + b:i*batch_size + b + foresee_date])\n",
        "      \n",
        "    train_batches.append((torch.cat(data_batch,axis=1),torch.cat(train_batch,axis=0)))\n",
        "\n",
        "  return data_train_np, data_val_np, target_train_np, target_val_np, train_batches ,data_batch, data_val_tensor, data_train_tensor,target_train_tensor,target_val_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlPUoze2eZij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_train_np, data_val_np, target_train_np, target_val_np, train_batches, data_batch = data_preprocessing(data_norm, time_steps, foresee_date)\n",
        "# train(time_steps, foresee_date, train_batches, model, optimizer, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IUP_FaVjoWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# slice_point = 800\n",
        "\n",
        "# data_train_np = data_norm[:slice_point,:]\n",
        "\n",
        "# data_val_np = data_norm[slice_point:,:]\n",
        "# data_train_tensor = torch.from_numpy(np.expand_dims(data_train_np, axis=1)).to(device)\n",
        "# data_val_tensor = torch.from_numpy(np.expand_dims(data_val_np, axis=1)).to(device)\n",
        "\n",
        "# target_train_np = data_train_np[time_steps:,[0,2]]\n",
        "\n",
        "# target_train_tensor = torch.from_numpy(np.expand_dims(target_train_np, axis=0)).to(device)\n",
        "# target_val_np = data_val_np[time_steps:,[0,2]]\n",
        "# target_val_tensor = torch.from_numpy(np.expand_dims(target_val_np, axis=0)).to(device)\n",
        "\n",
        "# train_batches = []\n",
        "\n",
        "# for i in range((slice_point - time_steps - (foresee_date - 1)) // batch_size):\n",
        "#   data_batch = []\n",
        "#   train_batch = []\n",
        "#   for b in range(batch_size):\n",
        "#     data_batch.append(data_train_tensor[i*batch_size + b:i*batch_size + b + time_steps,:,:])\n",
        "#     train_batch.append(target_train_tensor[:,i*batch_size + b:i*batch_size + b + foresee_date])\n",
        "    \n",
        "#   train_batches.append((torch.cat(data_batch,axis=1),torch.cat(train_batch,axis=0)))\n",
        "\n",
        "# = data_preprocessing(data_norm)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VtBWgQU3sA2",
        "colab_type": "text"
      },
      "source": [
        "# **Model training**\n",
        "이전 모델의 loss보다 낮은 loss를 기록할 경우 자동 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3lpr12OMShP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_point = 1       ##mamximum = 5040\n",
        "count = 0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6HSYrWmlklC",
        "colab_type": "code",
        "outputId": "033c0148-578c-4176-eb41-3c0a1a040908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir = \"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/\"\n",
        "lr_list = [lr, lr/3, lr/5]\n",
        "hidden_list = list(range(10,50,5))\n",
        "num_layer_list = list(range(2,4))\n",
        "foresee_date_list = list(range(1,6))\n",
        "time_step_list = list(range(10,31))\n",
        "\n",
        "\n",
        "\n",
        "# optimizer_list = [optim.Adam(model.parameters(), lr = lr), optim.SGD(model.parameters(), lr = lr)]\n",
        "\n",
        "                     \n",
        "#try:\n",
        "for num_layer2 in num_layer_list:\n",
        "  for h_layer2 in hidden_list:\n",
        "    model = LSTM_sequential(input_size, hidden, dropout_rate, num_layer2)\n",
        "    model = model.to(device)\n",
        "    model = model.double()\n",
        "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    criterion = criterion.to(device)\n",
        "    model_state, pre_train_loss =  call_model(model, num_layer2, h_layer2)\n",
        "    model.load_state_dict(model_state)\n",
        "    for time_step2 in time_step_list:\n",
        "      for foresee_date2 in foresee_date_list:\n",
        "        data_train_np, data_val_np, target_train_np, target_val_np, train_batches ,data_batch, data_val_tensor, data_train_tensor,target_train_tensor,target_val_tensor = data_preprocessing(data_norm, time_step2,foresee_date2)\n",
        "        for lr2 in lr_list:\n",
        "          count +=1\n",
        "          #print(count)\n",
        "          if count < save_point: continue         #저장지점까지 continue\n",
        "\n",
        "          # if lr < lr2 and lr != lr_list[-1]:      #만약 불러온 모델의 lr이 더 낮을경우 그 lr에 대한 학습은 건너뜀, 제일 작은 lr경우는 학습함\n",
        "          #   continue\n",
        "          print(\"lr:\",lr2, \"foresee_date:\",foresee_date2, \"h_layer:\",h_layer2, \"num_layer:\",num_layer2)\n",
        "          if shuffle:\n",
        "            random.shuffle(train_batches)\n",
        "            for ep in range(100):\n",
        "              optimizer = optim.Adam(model.parameters(), lr = lr2)\n",
        "              start_time = time.time()\n",
        "              train_loss = train(time_step2, foresee_date2, train_batches, model, optimizer, criterion)\n",
        "              end_time = time.time()\n",
        "              if ep%10 == 0:\n",
        "                print(train_loss)\n",
        "                print(end_time - start_time)\n",
        "                if train_loss < pre_train_loss and train_loss < 0.003:      #이전보다 loss가 낮으면 저장함.\n",
        "                  pre_train_loss = train_loss           #제일 낮은 loss 갱신\n",
        "                  if not os.path.exists(dir):\n",
        "                    os.makedirs(dir)          #dir가 없으면 만들어서 저장\n",
        "                  save_dict = {\"model_state\":model.state_dict(),\n",
        "                                \"loss\":train_loss,\n",
        "                                \"lr\": lr2,\n",
        "                                \"optimizer\": optimizer,\n",
        "                                \"hidden_layer\": h_layer2,\n",
        "                                \"num_layers\" : num_layer2,\n",
        "                                \"time_step\":time_step2,\n",
        "                                \"foresee_date\":foresee_date2}\n",
        "                  model_name = dir+str(model)+\"-\"+str(num_layer2)+'-'+str(h_layer2)+\"-\"+'loss_'+str(int(train_loss*1000))+\".pt\"         #여러명이 돌릴경우 직관성을 위해 filename에 loss도 포함\n",
        "                  torch.save(save_dict,model_name)\n",
        "                  print(\"save\",model_name)\n",
        "                  loss_train, predictions_train = evaluate(time_step2, foresee_date2, data_train_tensor, target_train_tensor, model, criterion)\n",
        "                  view_plot(predictions_train, target_train_np)\n",
        "                  loss_val, predictions_val = evaluate(time_step2,foresee_date2, data_val_tensor, target_val_tensor, model, criterion)\n",
        "                  view_plot_val(predictions_val, target_val_np)\n",
        "# except Exception as inst:\n",
        "#   print(inst)\n",
        "#   print(\"your check point:\", count)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "불러온 모델 LSTM_sequential-2-10-loss_2.pt pre_train_loss:  0.002111304959446665\n",
            "lr: 0.0005 foresee_date: 1 h_layer: 10 num_layer: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0024017244901398814\n",
            "0.6377215385437012\n",
            "0.002310123177862386\n",
            "0.6220149993896484\n",
            "0.002484726599044893\n",
            "0.6147279739379883\n",
            "0.002550313248962323\n",
            "0.6135392189025879\n",
            "0.0026887682078099947\n",
            "0.6161890029907227\n",
            "0.0025237981778805435\n",
            "0.6285994052886963\n",
            "0.0023294144798994038\n",
            "0.6241064071655273\n",
            "0.002336970703972355\n",
            "0.5996582508087158\n",
            "0.002408729352007488\n",
            "0.6075229644775391\n",
            "0.0025232643379691565\n",
            "0.613436222076416\n",
            "lr: 0.00016666666666666666 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.0023857637018573864\n",
            "0.6216869354248047\n",
            "0.00221907660242061\n",
            "0.6214368343353271\n",
            "0.002355576273970029\n",
            "0.6037538051605225\n",
            "0.002194492711615605\n",
            "0.6193337440490723\n",
            "0.0022660368381096007\n",
            "0.6191487312316895\n",
            "0.002451359743644762\n",
            "0.6271615028381348\n",
            "0.0022402746594114664\n",
            "0.6077039241790771\n",
            "0.0020989794548117407\n",
            "0.5985569953918457\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-loss_2.pt\n",
            "0.00237914694420562\n",
            "0.6279683113098145\n",
            "0.002289699671872271\n",
            "0.6153607368469238\n",
            "lr: 0.0001 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.0023326726264798936\n",
            "0.6190307140350342\n",
            "0.002279759945196127\n",
            "0.6084120273590088\n",
            "0.0023120806331234562\n",
            "0.6068999767303467\n",
            "0.002149020362336538\n",
            "0.6076691150665283\n",
            "0.002432967027486273\n",
            "0.6067383289337158\n",
            "0.002302409588861336\n",
            "0.5957505702972412\n",
            "0.0021097378835763176\n",
            "0.6079001426696777\n",
            "0.002089391043504472\n",
            "0.6001996994018555\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-loss_2.pt\n",
            "0.0022097077975371743\n",
            "0.6061279773712158\n",
            "0.002324960805871211\n",
            "0.6029083728790283\n",
            "lr: 0.0005 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.0023409821714076916\n",
            "0.9538311958312988\n",
            "0.0023358025512810686\n",
            "0.9697873592376709\n",
            "0.0024450254798756323\n",
            "0.9390554428100586\n",
            "0.0024739293041777387\n",
            "1.0018646717071533\n",
            "0.002182647674402158\n",
            "0.9581375122070312\n",
            "0.0023641959446589855\n",
            "0.9233956336975098\n",
            "0.0023280904382835896\n",
            "0.9256620407104492\n",
            "0.0023921578151554945\n",
            "0.9340698719024658\n",
            "0.002269420614576811\n",
            "0.9509353637695312\n",
            "0.002475353601031136\n",
            "0.9397306442260742\n",
            "lr: 0.00016666666666666666 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.0022686269312099886\n",
            "0.9530627727508545\n",
            "0.0022674018546280897\n",
            "0.9234452247619629\n",
            "0.0022887839968482575\n",
            "0.8868353366851807\n",
            "0.0024110349323097457\n",
            "0.9352731704711914\n",
            "0.0023488083674234835\n",
            "0.9469583034515381\n",
            "0.002250164037104769\n",
            "0.9046602249145508\n",
            "0.002378871216621542\n",
            "0.9043095111846924\n",
            "0.0023346626474583607\n",
            "0.889420747756958\n",
            "0.002191052803763767\n",
            "0.9276177883148193\n",
            "0.002367429936295281\n",
            "0.9403307437896729\n",
            "lr: 0.0001 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.002378197799609192\n",
            "0.9230611324310303\n",
            "0.0022645727079345637\n",
            "0.9159021377563477\n",
            "0.0022381437976553534\n",
            "0.9220342636108398\n",
            "0.002361241585958539\n",
            "0.9282608032226562\n",
            "0.0023425624852848916\n",
            "0.9137856960296631\n",
            "0.002305069048192846\n",
            "0.9125063419342041\n",
            "0.002221077136348499\n",
            "0.8994438648223877\n",
            "0.002127670282391164\n",
            "0.9273240566253662\n",
            "0.0022724295724268306\n",
            "0.8951621055603027\n",
            "0.002260228334683991\n",
            "0.8930814266204834\n",
            "lr: 0.0005 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.0025981195388926175\n",
            "1.2557435035705566\n",
            "0.0023882416411853268\n",
            "1.226294994354248\n",
            "0.0024816398481831586\n",
            "1.2314577102661133\n",
            "0.0025365755693262473\n",
            "1.2348346710205078\n",
            "0.0024654358400863644\n",
            "1.2461373805999756\n",
            "0.002483028322877268\n",
            "1.3072361946105957\n",
            "0.0025132547670526015\n",
            "1.2131283283233643\n",
            "0.00248276865343714\n",
            "1.224949598312378\n",
            "0.002452286682870063\n",
            "1.230987310409546\n",
            "0.002436070805186203\n",
            "1.2240626811981201\n",
            "lr: 0.00016666666666666666 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.0023548571510497267\n",
            "1.252136468887329\n",
            "0.002594247166815673\n",
            "1.2495605945587158\n",
            "0.0023812608255253005\n",
            "1.2227692604064941\n",
            "0.0022312848405843673\n",
            "1.2182722091674805\n",
            "0.002455725453741725\n",
            "1.2448174953460693\n",
            "0.002554044366814851\n",
            "1.2516686916351318\n",
            "0.002438439395668692\n",
            "1.2040128707885742\n",
            "0.0023813878706713935\n",
            "1.2084460258483887\n",
            "0.002454006231116432\n",
            "1.233551263809204\n",
            "0.0023457608344885695\n",
            "1.2065024375915527\n",
            "lr: 0.0001 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.002386906352311823\n",
            "1.2059869766235352\n",
            "0.0022549929486157237\n",
            "1.2256050109863281\n",
            "0.0024602268271162403\n",
            "1.2058956623077393\n",
            "0.0024005460369080616\n",
            "1.217932939529419\n",
            "0.0023190394145362163\n",
            "1.218975305557251\n",
            "0.002295061511310533\n",
            "1.228635549545288\n",
            "0.0023585805095928314\n",
            "1.2309060096740723\n",
            "0.0022604176905316113\n",
            "1.223832607269287\n",
            "0.0023441862975183566\n",
            "1.233159065246582\n",
            "0.0024900407880084595\n",
            "1.218306541442871\n",
            "lr: 0.0005 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.002511906258509895\n",
            "1.563241720199585\n",
            "0.00262691133560122\n",
            "1.5605592727661133\n",
            "0.0026355231101091816\n",
            "1.5433056354522705\n",
            "0.0025334609792996583\n",
            "1.5371334552764893\n",
            "0.0026202739811092266\n",
            "1.5465095043182373\n",
            "0.00250565310269945\n",
            "1.5472750663757324\n",
            "0.002572045946767803\n",
            "1.5562303066253662\n",
            "0.002531262336049084\n",
            "1.5576775074005127\n",
            "0.0025199345988445522\n",
            "1.5490751266479492\n",
            "0.0027111479312147218\n",
            "1.5335617065429688\n",
            "lr: 0.00016666666666666666 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.002493790334561557\n",
            "1.5519185066223145\n",
            "0.0025022496227047977\n",
            "1.571364402770996\n",
            "0.002550916453120476\n",
            "1.5489544868469238\n",
            "0.002349882517430436\n",
            "1.5427579879760742\n",
            "0.002353290235184697\n",
            "1.5523712635040283\n",
            "0.00244047579093798\n",
            "1.5588555335998535\n",
            "0.002411585752168897\n",
            "1.5795705318450928\n",
            "0.0024052699442231474\n",
            "1.5502638816833496\n",
            "0.0023952624347286155\n",
            "1.5432167053222656\n",
            "0.0024722674355817766\n",
            "1.5178196430206299\n",
            "lr: 0.0001 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.002416241029309178\n",
            "1.5261237621307373\n",
            "0.002336537031649524\n",
            "1.569749355316162\n",
            "0.0023349124015080262\n",
            "1.549339771270752\n",
            "0.002371089914960478\n",
            "1.5429997444152832\n",
            "0.0024523466343735366\n",
            "1.5273704528808594\n",
            "0.0023131851787323585\n",
            "1.5515296459197998\n",
            "0.002390660751291256\n",
            "1.555802345275879\n",
            "0.002390646671409151\n",
            "1.5517940521240234\n",
            "0.0023394443343872627\n",
            "1.537454605102539\n",
            "0.0024578530800930956\n",
            "1.5517044067382812\n",
            "lr: 0.0005 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.002642954465828771\n",
            "1.8704562187194824\n",
            "0.002901616443723385\n",
            "1.9017956256866455\n",
            "0.0028127907189048787\n",
            "1.8690578937530518\n",
            "0.002766979105696709\n",
            "1.8662075996398926\n",
            "0.0027837361707364816\n",
            "1.872225046157837\n",
            "0.0027534006952588223\n",
            "1.870307207107544\n",
            "0.002746842616469961\n",
            "1.8877685070037842\n",
            "0.002744762527871246\n",
            "1.8803296089172363\n",
            "0.0026840844516072934\n",
            "1.8750243186950684\n",
            "0.0026629922603668373\n",
            "1.90043044090271\n",
            "lr: 0.00016666666666666666 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.0024466319485605182\n",
            "1.9140901565551758\n",
            "0.0025826605499751068\n",
            "1.8693351745605469\n",
            "0.002552325271663393\n",
            "1.9007940292358398\n",
            "0.0025570587910918752\n",
            "1.863274097442627\n",
            "0.002556354066070612\n",
            "1.881842851638794\n",
            "0.0025733601259891104\n",
            "1.8900864124298096\n",
            "0.0024203098134862907\n",
            "1.8909721374511719\n",
            "0.002528068244682904\n",
            "1.924959421157837\n",
            "0.002554841062776017\n",
            "1.8916118144989014\n",
            "0.002446924412343263\n",
            "1.8918383121490479\n",
            "lr: 0.0001 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.002507922375191427\n",
            "1.907118558883667\n",
            "0.0024423751713656084\n",
            "1.8841478824615479\n",
            "0.0025525809750618846\n",
            "1.8682711124420166\n",
            "0.0025055680627797893\n",
            "1.8893048763275146\n",
            "0.0024592616764204478\n",
            "1.8724048137664795\n",
            "0.0023473549383359466\n",
            "1.8904316425323486\n",
            "0.0025516462493007652\n",
            "1.884873628616333\n",
            "0.0023823017741146273\n",
            "1.9112586975097656\n",
            "0.0024388596756659458\n",
            "1.8810863494873047\n",
            "0.002505679911461708\n",
            "1.8885059356689453\n",
            "lr: 0.0005 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.0022416516329442767\n",
            "0.6020023822784424\n",
            "0.0024349511330315618\n",
            "0.5915725231170654\n",
            "0.0024671823739104964\n",
            "0.5889534950256348\n",
            "0.002234524675723265\n",
            "0.595935583114624\n",
            "0.0023476785108987003\n",
            "0.5907304286956787\n",
            "0.002787547465251226\n",
            "0.5899670124053955\n",
            "0.0025942581292396853\n",
            "0.5942819118499756\n",
            "0.0024565435880012894\n",
            "0.5926907062530518\n",
            "0.002257142516262198\n",
            "0.5885171890258789\n",
            "0.002268697676078939\n",
            "0.5885891914367676\n",
            "lr: 0.00016666666666666666 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.00233940395449865\n",
            "0.6088476181030273\n",
            "0.0021487096154808208\n",
            "0.592278003692627\n",
            "0.002282478422356183\n",
            "0.5961630344390869\n",
            "0.0023612570283506897\n",
            "0.5943560600280762\n",
            "0.002193109443538633\n",
            "0.5884313583374023\n",
            "0.002239993242017044\n",
            "0.5844054222106934\n",
            "0.0022432392977854675\n",
            "0.5944230556488037\n",
            "0.0022380024576267358\n",
            "0.6021249294281006\n",
            "0.002201492694241187\n",
            "0.5950496196746826\n",
            "0.002262530241488806\n",
            "0.5879917144775391\n",
            "lr: 0.0001 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.0022182752423858545\n",
            "0.6226317882537842\n",
            "0.0021615576047527823\n",
            "0.5871560573577881\n",
            "0.0021978818127536283\n",
            "0.5920829772949219\n",
            "0.002459749771422701\n",
            "0.5914390087127686\n",
            "0.0021248983348616792\n",
            "0.5816168785095215\n",
            "0.0021760413033544723\n",
            "0.5771093368530273\n",
            "0.002208728170377694\n",
            "0.5856914520263672\n",
            "0.00227155145945321\n",
            "0.5968787670135498\n",
            "0.0022096831242929857\n",
            "0.6025736331939697\n",
            "0.0020522928714333108\n",
            "0.581641674041748\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-loss_2.pt\n",
            "lr: 0.0005 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.002334025556504953\n",
            "0.9445629119873047\n",
            "0.0024630548560184568\n",
            "0.9303820133209229\n",
            "0.0022739847835948853\n",
            "0.9191145896911621\n",
            "0.0021636881741577256\n",
            "0.9374821186065674\n",
            "0.0024195157264620144\n",
            "0.9749252796173096\n",
            "0.0023107484184079602\n",
            "0.9158427715301514\n",
            "0.0022442173005505837\n",
            "0.9232854843139648\n",
            "0.002231929855964471\n",
            "0.933732271194458\n",
            "0.0023261058252646233\n",
            "0.9220371246337891\n",
            "0.0021074348518119452\n",
            "0.9284098148345947\n",
            "lr: 0.00016666666666666666 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.0022054469103207383\n",
            "0.9207103252410889\n",
            "0.0020848540597892995\n",
            "0.9268567562103271\n",
            "0.0021571203600704468\n",
            "0.9072961807250977\n",
            "0.002103977657679951\n",
            "0.9352850914001465\n",
            "0.0021022221218006646\n",
            "0.9229400157928467\n",
            "0.002014807999597015\n",
            "0.9275572299957275\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-loss_2.pt\n",
            "0.00212076308380648\n",
            "0.9150593280792236\n",
            "0.0021032192147738514\n",
            "0.938678503036499\n",
            "0.002188802682553252\n",
            "0.90627121925354\n",
            "0.0019562578356307194\n",
            "0.9286303520202637\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-loss_1.pt\n",
            "lr: 0.0001 foresee_date: 2 h_layer: 10 num_layer: 2\n",
            "0.002257402600627177\n",
            "0.9196319580078125\n",
            "0.0020791864592113705\n",
            "0.9125697612762451\n",
            "0.002173444741074817\n",
            "0.9375607967376709\n",
            "0.002080761392177554\n",
            "0.9282722473144531\n",
            "0.0020564790484451224\n",
            "0.9252719879150391\n",
            "0.00196459097200319\n",
            "0.9310591220855713\n",
            "0.0020289228713782498\n",
            "0.9371209144592285\n",
            "0.0018940853345029225\n",
            "0.9200053215026855\n",
            "save /content/gdrive/My Drive/Colab Notebooks/stock_project/Models/LSTM_sequential-2-10-loss_1.pt\n",
            "0.0020763599525750035\n",
            "0.9098289012908936\n",
            "0.002229726486821116\n",
            "0.9251434803009033\n",
            "lr: 0.0005 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.002136827262917924\n",
            "1.2704451084136963\n",
            "0.002422600597759784\n",
            "1.247739553451538\n",
            "0.0021944873245509735\n",
            "1.2652990818023682\n",
            "0.002236310352930326\n",
            "1.2676305770874023\n",
            "0.0022006955416215613\n",
            "1.2576391696929932\n",
            "0.0022707617616501397\n",
            "1.3137035369873047\n",
            "0.0023269915725900045\n",
            "1.2720813751220703\n",
            "0.0022813341401163433\n",
            "1.257516622543335\n",
            "0.0022349127505022328\n",
            "1.2489948272705078\n",
            "0.0021714446017757996\n",
            "1.2730743885040283\n",
            "lr: 0.00016666666666666666 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.002226688434201673\n",
            "1.2679710388183594\n",
            "0.002175852311788756\n",
            "1.2535021305084229\n",
            "0.0022607250957073608\n",
            "1.2734618186950684\n",
            "0.002197857015797783\n",
            "1.254995346069336\n",
            "0.0020889987776558368\n",
            "1.2510972023010254\n",
            "0.002076452271337236\n",
            "1.2498500347137451\n",
            "0.002062309927495926\n",
            "1.2648158073425293\n",
            "0.002052003788549055\n",
            "1.2892355918884277\n",
            "0.002051399381351162\n",
            "1.2570033073425293\n",
            "0.002053097943379904\n",
            "1.24717116355896\n",
            "lr: 0.0001 foresee_date: 3 h_layer: 10 num_layer: 2\n",
            "0.0021422967801890467\n",
            "1.2602782249450684\n",
            "0.002135207633055391\n",
            "1.2642862796783447\n",
            "0.0021858058352709907\n",
            "1.2618985176086426\n",
            "0.0021613320373811942\n",
            "1.268799066543579\n",
            "0.0021753621753476155\n",
            "1.2627532482147217\n",
            "0.0022103472506893626\n",
            "1.2620384693145752\n",
            "0.002078004009880226\n",
            "1.2482092380523682\n",
            "0.0021202794774424867\n",
            "1.2440855503082275\n",
            "0.002228078958402954\n",
            "1.2632012367248535\n",
            "0.002069196451090996\n",
            "1.2644288539886475\n",
            "lr: 0.0005 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.0023365735977764392\n",
            "1.6379806995391846\n",
            "0.0024891518235478725\n",
            "1.607464075088501\n",
            "0.0024220454803439346\n",
            "1.6215312480926514\n",
            "0.0023267623845517065\n",
            "1.614614725112915\n",
            "0.0023562334524156727\n",
            "1.634878158569336\n",
            "0.0023295623728546793\n",
            "1.5930767059326172\n",
            "0.002355330877482134\n",
            "1.600403070449829\n",
            "0.002396460054871816\n",
            "1.6401946544647217\n",
            "0.002346980596005596\n",
            "1.6133630275726318\n",
            "0.002389969043286266\n",
            "1.6487829685211182\n",
            "lr: 0.00016666666666666666 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.0022923358916919585\n",
            "1.620934247970581\n",
            "0.0021669840801153543\n",
            "1.6190073490142822\n",
            "0.0020942109128991417\n",
            "1.621103048324585\n",
            "0.0021714856630937925\n",
            "1.5964434146881104\n",
            "0.0021340291180611697\n",
            "1.6047606468200684\n",
            "0.002183823510419677\n",
            "1.6420378684997559\n",
            "0.002115435928055824\n",
            "1.6004211902618408\n",
            "0.0022058837130875435\n",
            "1.6253325939178467\n",
            "0.002237372409474502\n",
            "1.6109213829040527\n",
            "0.00236821439388163\n",
            "1.6816649436950684\n",
            "lr: 0.0001 foresee_date: 4 h_layer: 10 num_layer: 2\n",
            "0.002256737827340116\n",
            "1.6242456436157227\n",
            "0.002204250000659539\n",
            "1.6122591495513916\n",
            "0.002232475936073414\n",
            "1.6118791103363037\n",
            "0.0022660349063642186\n",
            "1.6108837127685547\n",
            "0.0021642105652303597\n",
            "1.6232631206512451\n",
            "0.0021914028420800557\n",
            "1.6111178398132324\n",
            "0.00221098034782587\n",
            "1.6225543022155762\n",
            "0.0020869362431423675\n",
            "1.668708086013794\n",
            "0.002215684125346439\n",
            "1.6347177028656006\n",
            "0.0021271269788588356\n",
            "1.6319749355316162\n",
            "lr: 0.0005 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.002493346953070814\n",
            "1.9924228191375732\n",
            "0.0024385767114988325\n",
            "1.9748749732971191\n",
            "0.0025369177707958482\n",
            "1.954719066619873\n",
            "0.002355437704991455\n",
            "2.006509780883789\n",
            "0.0025472816476818628\n",
            "1.9602046012878418\n",
            "0.0024485094283388923\n",
            "1.9758951663970947\n",
            "0.002483748213903529\n",
            "1.9923646450042725\n",
            "0.002415433050277217\n",
            "2.011664390563965\n",
            "0.0024936005780157476\n",
            "2.0133273601531982\n",
            "0.0023825179389644698\n",
            "1.9903216361999512\n",
            "lr: 0.00016666666666666666 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.0020889826380235178\n",
            "1.9857985973358154\n",
            "0.0023220406021939683\n",
            "2.034848690032959\n",
            "0.002268784886068214\n",
            "1.989375352859497\n",
            "0.002176107924661442\n",
            "1.9796078205108643\n",
            "0.00225150352874482\n",
            "2.046588897705078\n",
            "0.002255495277072078\n",
            "2.0415992736816406\n",
            "0.002263855212481745\n",
            "1.9879286289215088\n",
            "0.0022621117776450653\n",
            "2.0193493366241455\n",
            "0.0022340733967482307\n",
            "2.0113673210144043\n",
            "0.002273290390630003\n",
            "1.9987595081329346\n",
            "lr: 0.0001 foresee_date: 5 h_layer: 10 num_layer: 2\n",
            "0.002079176343677163\n",
            "1.9834182262420654\n",
            "0.002223439840542281\n",
            "1.98795485496521\n",
            "0.0023261499996553876\n",
            "2.0708811283111572\n",
            "0.0022364794275161154\n",
            "2.0041542053222656\n",
            "0.0023255903667850093\n",
            "1.9933693408966064\n",
            "0.002262808258816392\n",
            "1.9732043743133545\n",
            "0.002177870537723271\n",
            "1.974426507949829\n",
            "0.002256946840903355\n",
            "2.016676664352417\n",
            "0.0022039713494644174\n",
            "2.011394500732422\n",
            "0.0022091213386098837\n",
            "1.9944696426391602\n",
            "lr: 0.0005 foresee_date: 1 h_layer: 10 num_layer: 2\n",
            "0.00254717342286996\n",
            "0.6228091716766357\n",
            "0.002366781286484986\n",
            "0.6198747158050537\n",
            "0.0023595967015212177\n",
            "0.6093201637268066\n",
            "0.002490242991680432\n",
            "0.637941837310791\n",
            "0.002457382608802596\n",
            "0.6190204620361328\n",
            "0.0022570345003216823\n",
            "0.5979611873626709\n",
            "0.002245144922876977\n",
            "0.6141202449798584\n",
            "0.0022782951910692707\n",
            "0.6132619380950928\n",
            "0.0024864293782252936\n",
            "0.6078338623046875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpqt2stv2h8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#direc = \"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/model1.py\"\n",
        "#torch.save(model.state_dict(), direc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8z5E51e4VyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model2 = LSTM_sequential(input_size, hidden, dropout_rate).to(device).double()\n",
        "#model2.load_state_dict(torch.load(\"/content/gdrive/My Drive/Colab Notebooks/stock_project/Models/model1.py\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxmCwkA-Zp4E",
        "colab_type": "code",
        "outputId": "9448315e-7648-4c8c-b12b-d3572c1dc624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "# plt.plot(target_train_np[:,1])\n",
        "# plt.plot(predictions_train[:,0,1])\n",
        "view_plot(predictions_train, target_train_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7421185f25be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforesee_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plt.plot(target_train_np[:,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plt.plot(predictions_train[:,0,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mview_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_train_tensor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beElDM1fM916",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "#plt.figure(figsize=(100, 5))\n",
        "\n",
        "view_plot(predictions_train, target_train_np)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8IsWxsWbCf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(target_train_np[d - 1:,1])\n",
        "#print(predictions_train[:,d-1,1])\n",
        "#print(pre_with_time)\n",
        "# print(predictions_train[:,:,1][:100])\n",
        "# print(predictions_train[:,:,0][0])\n",
        "#print(predictions_train[:2,:,1])\n",
        "# print(predictions_train.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jSKakYB2N6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps,foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "view_plot(predictions_train, target_train_np)\n",
        "# plt.plot(target_train_np[d - 1:,1])\n",
        "# plt.plot(predictions_train[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY5lFdlI2Iaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps,foresee_date, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "\n",
        "view_plot_val(predictions_val, target_val_np)\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn3Queky5Yyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx0r5h1H2Pzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps,foresee_date, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "view_plot_val(predictions_val, target_val_np)\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Ey9k02og27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = lr/3)\n",
        "\n",
        "for ep in range(200):\n",
        "  start_time = time.time()\n",
        "  if shuffle:\n",
        "    random.shuffle(train_batches)\n",
        "  train_loss = train(time_steps,foresee_date, train_batches, model, optimizer, criterion)\n",
        "  end_time = time.time()\n",
        "  if ep%50 == 0:\n",
        "    print(train_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap9DL0vS2nE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps,foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "view_plot(predictions_train, target_train_np)\n",
        "# plt.plot(target_train_np[d - 1:,1])\n",
        "# plt.plot(predictions_train[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edip56o82m-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps,foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "view_plot(predictions_train, target_train_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1hNPHJ42m2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps,foresee_date, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "view_plot_val(predictions_val, target_val_np)\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-SF9ORn2mtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps,foresee_date, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "view_plot_val(predictions_val, target_val_np)\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNzDTD9fv0Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = lr/5)\n",
        "\n",
        "for ep in range(200):\n",
        "  start_time = time.time()\n",
        "  train_loss = train(time_steps,foresee_date, train_batches, model, optimizer, criterion)\n",
        "  end_time = time.time()\n",
        "  if ep%50 == 0:\n",
        "    print(train_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isgt8i_gWWth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps,foresee_date, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "\n",
        "# print(predictions_train.shape)\n",
        "# print(target_train_np.shape)\n",
        "\n",
        "# plt.plot(target_train_np[d - 1:,1][300:500])\n",
        "# plt.plot(predictions_train[:,d - 1,1][300:500])\n",
        "\n",
        "# print(target_train_np[d - 1,0])\n",
        "# print(predictions_train[0,d-1,0])\n",
        "view_plot(predictions_train, target_train_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_D50oC1d2PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps, foresee_date,data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "# d = 5\n",
        "\n",
        "# plt.plot(target_val_np[d - 1:,1])\n",
        "# plt.plot(predictions_val[:,d - 1,1])\n",
        "view_plot_val(predictions_val, target_val_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1GRFauTG8w0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}