{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Model v.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Concarne2/Stock-project/blob/master/Basic_Model_v_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0hF7M50RySa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpbeiVKHV0KG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing data from url\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/Concarne2/stock_data/master/DATA/sk%ED%95%98%EC%9D%B4%EB%8B%89%EC%8A%A4(%EC%88%98%EC%A0%95).csv\"\n",
        "csv_df=pd.read_csv(url)\n",
        "\n",
        "#  0     1    2    3     4      5    6    7\n",
        "# year,month,day,close,volume,start,high,low\n",
        "\n",
        "\n",
        "csv_np_raw = csv_df.to_numpy()\n",
        "row,col = np.shape(csv_np_raw)\n",
        "\n",
        "for i in range(row):\n",
        "  for j in range(3,col):\n",
        "    csv_np_raw[i][j] = csv_np_raw[i][j].replace(\",\",\"\")\n",
        "\n",
        "full_data_np = np.flip(csv_np_raw.astype(int),axis=0)\n",
        "data_np = full_data_np[:,[5,3,6,7,4]]\n",
        "#data_np = full_data_np[:,[6,3,7,4]]\n",
        "\n",
        "print(data_np.shape)\n",
        "#plt.plot(data_np[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VswRwOMSLPcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize data\n",
        "\n",
        "#data_min = np.min(data_np[:,1])\n",
        "#data_scale = np.max(data_np[:,1]) - np.min(data_np[:,1])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data_np)\n",
        "data_norm = scaler.transform(data_np)\n",
        "data_norm = np.insert(data_norm,0,np.arange(data_norm.shape[0]),axis=1)\n",
        "#data = torch.from_numpy(data_norm)\n",
        "#plt.plot(data_norm[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTKTvc8yn05A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoreBasicLSTM(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, output_size):\n",
        "    super().__init__()\n",
        "    self.date = output_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = output_size)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(inputs)\n",
        "    output = self.drop(hidden.squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXlAPYcri7LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoreBasicLSTM_timestamp_processing(nn.Module):   \n",
        "  def __init__(self, input_size, hidden, drop, output_size):\n",
        "    super().__init__()\n",
        "    self.date = output_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden)\n",
        "    self.drop = nn.Dropout(p = drop)\n",
        "    self.fclayers = nn.Sequential(\n",
        "        nn.Softsign(),\n",
        "        nn.Linear(in_features = hidden, out_features = output_size)\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    input_without_timestamp = inputs[:,:,1:]\n",
        "    batch_size = inputs\n",
        "    \n",
        "    _,(hidden,_) = self.lstm(input_without_timestamp)\n",
        "    output = self.drop(hidden.squeeze(0))\n",
        "    output = self.fclayers(output).squeeze(0)\n",
        "    print(output.size())\n",
        "    output = output.view(self.date,1)\n",
        "    timestamps = torch.from_numpy(np.arange(self.date) + inputs[-1,:,0].item() + 1).view(self.date,1)\n",
        "    \n",
        "    return torch.cat([timestamps,output],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNUIr_wMZNK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(time_steps, data_target_batches, model, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  #prediction_list=[]\n",
        "  batch_amount = len(data_target_batches)\n",
        "  batch_size = list(data_target_batches[0][0].size())[1]\n",
        "  date = model.date\n",
        "  model.train()\n",
        "  \n",
        "  for data, target in data_target_batches:\n",
        "    \n",
        "    assert target[0,0,0].item() == (data[-1,0,0].item() + 1)\n",
        "    \n",
        "    optimizer.zero_grad()   \n",
        "    \n",
        "    data_without_timestamp = data[:,:,1:]\n",
        "    \n",
        "    prediction_batch = model(data_without_timestamp)\n",
        "    #for p in prediction_batch:\n",
        "    #  prediction_list.append(p.item())\n",
        "    target_without_timestamp = torch.squeeze(target[:,:,1])\n",
        "    loss = criterion(target_without_timestamp, prediction_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / batch_amount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8SP9jUcowZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(time_steps, data, target, model, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  predictions=[]\n",
        "  \n",
        "  date = model.date\n",
        "  \n",
        "  model.eval()\n",
        "  num_tries = list(target.size())[1] - (date - 1)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i in range(num_tries):\n",
        "      input_data = data[i:i+time_steps,:]\n",
        "      prediction = torch.squeeze(model(input_data[:,:,1:]))\n",
        "      \n",
        "      timestamps = torch.from_numpy(np.arange(date) + input_data[-1,0,0].item() + 1).to(device).view(date,1)\n",
        "      \n",
        "      prediction_with_time = torch.cat([timestamps,prediction.view(date,1)],axis=1)\n",
        "      \n",
        "      predictions.append(prediction_with_time.tolist())\n",
        "      loss = criterion(torch.squeeze(target)[i:i+date,1],prediction)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "    \n",
        "  return epoch_loss/num_tries, np.array(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX_UXoojRrfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.03\n",
        "time_steps = 30\n",
        "epoch = 50\n",
        "batch_size = 5\n",
        "dropout_rate = 0.3\n",
        "\n",
        "input_size = 5 #open close high low volume\n",
        "#hidden1 = 100\n",
        "hidden = 25\n",
        "#fc = 15\n",
        "\n",
        "foresee_date = 5\n",
        "shuffle = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#model = BasicLSTM(input_size, hidden1, hidden2, fc)\n",
        "#model = BasicLSTM(input_size, hidden, fc)\n",
        "model = MoreBasicLSTM(input_size, hidden, dropout_rate, foresee_date)\n",
        "model = model.to(device)\n",
        "model = model.double()\n",
        "\n",
        "#optimizer = optim.SGD(model.parameters(), lr = lr)\n",
        "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "#criterion = nn.L1Loss()\n",
        "criterion = nn.MSELoss()\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IUP_FaVjoWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slice_point = 800\n",
        "\n",
        "data_train_np = data_norm[:slice_point,:]\n",
        "\n",
        "data_val_np = data_norm[slice_point:,:]\n",
        "data_train_tensor = torch.from_numpy(np.expand_dims(data_train_np, axis=1)).to(device)\n",
        "data_val_tensor = torch.from_numpy(np.expand_dims(data_val_np, axis=1)).to(device)\n",
        "\n",
        "target_train_np = data_train_np[time_steps:,[0,2]]\n",
        "\n",
        "target_train_tensor = torch.from_numpy(np.expand_dims(target_train_np, axis=0)).to(device)\n",
        "target_val_np = data_val_np[time_steps:,[0,2]]\n",
        "target_val_tensor = torch.from_numpy(np.expand_dims(target_val_np, axis=0)).to(device)\n",
        "\n",
        "train_batches = []\n",
        "\n",
        "for i in range((slice_point - time_steps - (foresee_date - 1)) // batch_size):\n",
        "  data_batch = []\n",
        "  train_batch = []\n",
        "  for b in range(batch_size):\n",
        "    data_batch.append(data_train_tensor[i*batch_size + b:i*batch_size + b + time_steps,:,:])\n",
        "    train_batch.append(target_train_tensor[:,i*batch_size + b:i*batch_size + b + foresee_date])\n",
        "    \n",
        "  train_batches.append((torch.cat(data_batch,axis=1),torch.cat(train_batch,axis=0)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6HSYrWmlklC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if shuffle:\n",
        "  random.shuffle(train_batches)\n",
        "for ep in range(300):\n",
        "  start_time = time.time()\n",
        "  \n",
        "  train_loss = train(time_steps, train_batches, model, optimizer, criterion)\n",
        "  end_time = time.time()\n",
        "  if ep%100 == 0:\n",
        "    print(train_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beElDM1fM916",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "plt.plot(target_train_np[d - 1:,1])\n",
        "plt.plot(predictions_train[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jSKakYB2N6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "plt.plot(target_train_np[d - 1:,1])\n",
        "plt.plot(predictions_train[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY5lFdlI2Iaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "\n",
        "plt.plot(target_val_np[d - 1:,1])\n",
        "plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx0r5h1H2Pzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "\n",
        "plt.plot(target_val_np[d - 1:,1])\n",
        "plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Ey9k02og27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = lr/3)\n",
        "\n",
        "for ep in range(200):\n",
        "  start_time = time.time()\n",
        "  if shuffle:\n",
        "    random.shuffle(train_batches)\n",
        "  train_loss = train(time_steps, train_batches, model, optimizer, criterion)\n",
        "  end_time = time.time()\n",
        "  if ep%50 == 0:\n",
        "    print(train_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap9DL0vS2nE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "plt.plot(target_train_np[d - 1:,1])\n",
        "plt.plot(predictions_train[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edip56o82m-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "plt.plot(target_train_np[d - 1:,1])\n",
        "plt.plot(predictions_train[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1hNPHJ42m2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 1\n",
        "\n",
        "plt.plot(target_val_np[d - 1:,1])\n",
        "plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-SF9ORn2mtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "\n",
        "plt.plot(target_val_np[d - 1:,1])\n",
        "plt.plot(predictions_val[:,d - 1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNzDTD9fv0Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = lr/5)\n",
        "\n",
        "for ep in range(200):\n",
        "  start_time = time.time()\n",
        "  train_loss = train(time_steps, train_batches, model, optimizer, criterion)\n",
        "  end_time = time.time()\n",
        "  if ep%50 == 0:\n",
        "    print(train_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isgt8i_gWWth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train, predictions_train = evaluate(time_steps, data_train_tensor, target_train_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "\n",
        "print(predictions_train.shape)\n",
        "print(target_train_np.shape)\n",
        "\n",
        "plt.plot(target_train_np[d - 1:,1][300:500])\n",
        "plt.plot(predictions_train[:,d - 1,1][300:500])\n",
        "\n",
        "print(target_train_np[d - 1,0])\n",
        "print(predictions_train[0,d-1,0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_D50oC1d2PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_val, predictions_val = evaluate(time_steps, data_val_tensor, target_val_tensor, model, criterion)\n",
        "\n",
        "d = 5\n",
        "\n",
        "plt.plot(target_val_np[d - 1:,1])\n",
        "plt.plot(predictions_val[:,d - 1,1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}